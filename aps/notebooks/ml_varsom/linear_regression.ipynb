{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION\n",
    "\n",
    "- is the simplest machine learning model\n",
    "- is used for finding linear relationship between target and one or more predictors\n",
    "- there are two types of linear regression:\n",
    "    - Simple (one feature)\n",
    "    - Multiple (two or more features) \n",
    "- The main idea of linear regression is to obtain a line that best fits the data. \n",
    "- That means finding the one line for which total prediction error (for all data points) are as small as possible. (Error is the distance between actual values and values predicted using regression line.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First linear regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll create a simple linear regression model - we saw that LSTAT and RM are two variables that are highly correlated with target. We will see how good predicteions we can get with just one feature - and how to decide which one of these features is better for estimating median house price? \n",
    "\n",
    "Step one is to divide our dataset into training and testing part - it is important to test our model against data that has never been used for training â€“ that tells us how the model might perform against data that it has not yet seen and it is meant to be representative of how the model might perform in the real world.\n",
    "\n",
    "That's why we will use only 70% of our data to train the model and then we'll use the rest of data (30%) to evaluate our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "pd.set_option(\"display.max_rows\",6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('varsom_ml_preproc.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.filter(['mountain_weather_wind_speed_num'])#, 'ZN', 'INDUS', 'CHAS', 'RM', 'AGE', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT'])\n",
    "y = df_data['danger_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f36db2a37fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m      \u001b[1;33m+\u001b[0m \u001b[1;34m\" + {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" * AGE\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" + {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" * RAD\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m      \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n    {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" * TAX\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" {0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" * PTRATIO\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m      + \" + {0:.2f}\".format(model_lr.coef_[9]) + \" * B\" + \" {0:.2f}\".format(model_lr.coef_[10]) + \" * LSTAT\")\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 222, test_size = 0.3) # split the data\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model_lr = lm.fit(X_train, y_train) # train the model\n",
    "\n",
    "predictions_lr = model_lr.predict(X_test) # predict values for test dataset\n",
    "\n",
    "print(\"Our third model:  \\n \\ny = {0:.2f}\".format(model_lr.intercept_) + \" {0:.2f}\".format(model_lr.coef_[0]) + \" * CRIM\"\n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[1]) + \" * ZN\" + \" + {0:.2f}\".format(model_lr.coef_[2]) + \" * INDUS\"\n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[3]) + \" + * CHAS\" + \" {0:.2f}\".format(model_lr.coef_[4]) + \" * RM\" \n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[5]) + \" * AGE\" + \" + {0:.2f}\".format(model_lr.coef_[6]) + \" * RAD\"\n",
    "     + \"\\n    {0:.2f}\".format(model_lr.coef_[7]) + \" * TAX\" + \" {0:.2f}\".format(model_lr.coef_[8]) + \" * PTRATIO\"\n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[9]) + \" * B\" + \" {0:.2f}\".format(model_lr.coef_[10]) + \" * LSTAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4694af095757>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m222\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df_data, random_state = 222, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # we are importing machine learning model we'll use\n",
    "\n",
    "lm1 = linear_model.LinearRegression()\n",
    "\n",
    "model_1 = lm1.fit(X_train_1, y_train_1) # we have just created a model! :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we said before, the model in this simple case is a line that has two parameters\n",
    "\n",
    "# so we ask: what are our estimated parameters? (alpha and beta?)\n",
    "\n",
    "print(\"Our first model:  y = {0:.2f}\".format(model_1.intercept_) + \" {0:.2f}\".format(model_1.coef_[0]) + \" * x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept: {0:.2f}\".format(model_1.intercept_))\n",
    "print(\"Extra price per extra unit of LSTAT: {0:.2f}\".format(model_1.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'd like is to predict house price for test data (data that model hasn't seen yet)\n",
    "\n",
    "predictions_1 = model_1.predict(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize our regression line\n",
    "\n",
    "plt.plot(X_test_1, y_test_1, 'o')\n",
    "plt.plot(X_test_1, predictions_1, color = 'red')\n",
    "plt.xlabel('% of lower status of the population')\n",
    "plt.ylabel('Median home value in $1000s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to visualize the estimated and real house values for all data points in test dataset\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(X_test_1,predictions_1, 'o')\n",
    "plt.xlabel('% of lower status of the population')\n",
    "plt.ylabel('Estimated home value in $1000s')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(X_test_1,y_test_1, 'o')\n",
    "plt.xlabel('% of lower status of the population')\n",
    "plt.ylabel('Median home value in $1000s')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaulate the performance of the model, we can compute the error between the real house value (`y_test_1`) and the predicted values we got form our model (`predictions_1`).\n",
    "\n",
    "One such metric is called **the residual sum of squares (RSS)**: \n",
    "\n",
    "![title](pictures/rss.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we define our RSS function\n",
    "\n",
    "def RSS(y, p):\n",
    "    return sum((y - p)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we calculate RSS: \n",
    "\n",
    "RSS_model_1 = RSS(y_test_1, predictions_1)\n",
    "\n",
    "RSS_model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number doesn't tell us much - is 7027 good? Is it bad? \n",
    "\n",
    "Unfortunatelly, there is no right answer - it depends on the data. Sometimes RSS of 7000 indicates very bad model, and sometimes 7000 is as good as it gets. \n",
    "\n",
    "That's why we use RSS when comparing models - the model with lowest RSS is the best. \n",
    "\n",
    "The other metrics we can use to evaluate our model is called **coefficient of determination**. \n",
    "\n",
    "It's denoted as $R^{2}$ and it is the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "To calculate it, we use *.score* function in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1.score(X_test_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that only 51% of variability is explained by our model. \n",
    "\n",
    "In general, $R^{2}$ is a number between 0 and 1 - the closer it is to 1, the better the model is. \n",
    "\n",
    "Since we got only 0.51, we can conclude that this is not a very good model. \n",
    "\n",
    "But we can try to build a model with second variable - RM - and check if we can get better result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More linear regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we just repeat everything as before \n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(boston_data[['RM']], boston_data.MEDV, \n",
    "                                                            random_state = 222, test_size = 0.3) # split the data\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model_2 = lm.fit(X_train_2, y_train_2) # train the model\n",
    "\n",
    "predictions_2 = model_2.predict(X_test_2) # predict values for test dataset\n",
    "\n",
    "print(\"Our second model:  y = {0:.2f}\".format(model_2.intercept_) + \" + {0:.2f}\".format(model_2.coef_[0]) + \" * x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize our regression line\n",
    "\n",
    "plt.plot(X_test_2, y_test_2, 'o')\n",
    "plt.plot(X_test_2, predictions_2, color = 'red')\n",
    "plt.xlabel('Average number of rooms')\n",
    "plt.ylabel('Median home value in $1000s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's calculate RSS and R^2\n",
    "\n",
    "print (RSS(y_test_2, predictions_2)) \n",
    "\n",
    "print (lm.score(X_test_2, y_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can compare our models \n",
    "\n",
    "print(\"RSS for first model is {0:.2f}\".format(RSS(y_test_1, predictions_1)) \n",
    "      + \", and RSS for second model is {0:.2f}\".format(RSS(y_test_2, predictions_2)) + '\\n' + '\\n' \n",
    "      + \"R^2 for first model is {0:.2f}\".format(lm1.score(X_test_1, y_test_1)) \n",
    "      + \", and R^2 for second model is {0:.2f}\".format(lm.score(X_test_2, y_test_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RSS is lower for second modell (and lower the RSS, better the model) and $R^{2}$ is higher for second modell (and we want $R^{2}$ as close to 1 as possible), both measures tells us that **second model is better**.\n",
    "\n",
    "However, difference is not big - out second model performs slightly better, but we still can't say it fits our data well. \n",
    "\n",
    "Next thing we can try is to build a model with all features we have available and see if using multiple features improves performace of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_data[['CRIM', 'ZN', 'INDUS', 'CHAS', 'RM', 'AGE', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']]\n",
    "y = boston_data[\"MEDV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 222, test_size = 0.3) # split the data\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model_lr = lm.fit(X_train, y_train) # train the model\n",
    "\n",
    "predictions_lr = model_lr.predict(X_test) # predict values for test dataset\n",
    "\n",
    "print(\"Our third model:  \\n \\ny = {0:.2f}\".format(model_lr.intercept_) + \" {0:.2f}\".format(model_lr.coef_[0]) + \" * CRIM\"\n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[1]) + \" * ZN\" + \" + {0:.2f}\".format(model_lr.coef_[2]) + \" * INDUS\"\n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[3]) + \" + * CHAS\" + \" {0:.2f}\".format(model_lr.coef_[4]) + \" * RM\" \n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[5]) + \" * AGE\" + \" + {0:.2f}\".format(model_lr.coef_[6]) + \" * RAD\"\n",
    "     + \"\\n    {0:.2f}\".format(model_lr.coef_[7]) + \" * TAX\" + \" {0:.2f}\".format(model_lr.coef_[8]) + \" * PTRATIO\"\n",
    "     + \" + {0:.2f}\".format(model_lr.coef_[9]) + \" * B\" + \" {0:.2f}\".format(model_lr.coef_[10]) + \" * LSTAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate the model\n",
    "\n",
    "print(\"RSS for the third model is {0:.2f}\".format(RSS(y_test, predictions_lr))  + '\\n' + '\\n' \n",
    "      + \"R^2 for the third model is {0:.2f}\".format(lm.score(X_test, y_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see improvement - RSS is 2000 less than for second model, and $R^{2}$ is 0.24 higher than for second model.\n",
    "\n",
    "So out of the three models we tested, we can see that third one (with *multiple features*) is performing the best. \n",
    "\n",
    "Of course, linear regression is not the only method we can use to solve this problems - there are more advanced methods like **decision trees, random forests and gradient boosted trees**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
