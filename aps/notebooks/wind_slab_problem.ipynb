{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# make sure the aps module is in the pythonpath\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from flatten_json import flatten\n",
    "\n",
    "APS_dir = str(Path.cwd().parents[1])\n",
    "if APS_dir not in sys.path:\n",
    "    sys.path.append(APS_dir)\n",
    "import aps.aps_io.get_forecasts as gf # replace with varsomdata-class\n",
    "\n",
    "#import aps.config.training_score as ts\n",
    "from aps.config.training_score import APSTrainingScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get API data\n",
    "Request necessary data from https://api01.nve.no/hydrology/forecast/avalanche/v4.0.0/api\n",
    "\n",
    "Explanation at http://api.nve.no/doc/snoeskredvarsel/#format\n",
    "\n",
    "Insert relevant data into SQLite database.\n",
    "\n",
    "General:\n",
    "- date\n",
    "- region\n",
    "- region-ID\n",
    "- danger level\n",
    "\n",
    "Avalanche problem:\n",
    "- avalanche problem name\n",
    "- avalanche problem order\n",
    "- trigger\n",
    "- probability\n",
    "- elevation\n",
    "\n",
    "Mountain weather:\n",
    "- avg. precipitation\n",
    "- max precipitation (most exposed area)\n",
    "- temperature (at diff. levels)\n",
    "- wind speed\n",
    "- wind direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api01.nve.no/hydrology/forecast/avalanche/v4.0.0/api/AvalancheWarningByRegion/Detail/3024/1/2017-12-01/2018-05-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>AvalancheDanger</th>\n",
       "      <th>AvalancheProblems_0_AvalCauseId</th>\n",
       "      <th>AvalancheProblems_0_AvalCauseName</th>\n",
       "      <th>AvalancheProblems_0_AvalProbabilityId</th>\n",
       "      <th>AvalancheProblems_0_AvalProbabilityName</th>\n",
       "      <th>AvalancheProblems_0_AvalPropagationId</th>\n",
       "      <th>AvalancheProblems_0_AvalPropagationName</th>\n",
       "      <th>AvalancheProblems_0_AvalTriggerSimpleId</th>\n",
       "      <th>AvalancheProblems_0_AvalTriggerSimpleName</th>\n",
       "      <th>...</th>\n",
       "      <th>RegionId</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionTypeId</th>\n",
       "      <th>RegionTypeName</th>\n",
       "      <th>SnowSurface</th>\n",
       "      <th>UtmEast</th>\n",
       "      <th>UtmNorth</th>\n",
       "      <th>UtmZone</th>\n",
       "      <th>ValidFrom</th>\n",
       "      <th>ValidTo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karsten@NVE</td>\n",
       "      <td>Forholdene er generelt stabile. I noen definer...</td>\n",
       "      <td>10</td>\n",
       "      <td>Nedføyket svakt lag med nysnø</td>\n",
       "      <td>3</td>\n",
       "      <td>Mulig</td>\n",
       "      <td>1</td>\n",
       "      <td>Få bratte heng</td>\n",
       "      <td>10</td>\n",
       "      <td>Stor tilleggsbelastning</td>\n",
       "      <td>...</td>\n",
       "      <td>3022</td>\n",
       "      <td>Trollheimen</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Mildvær har komprimert snødekket og dannet tyd...</td>\n",
       "      <td>210810</td>\n",
       "      <td>6991060</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-01T00:00:00</td>\n",
       "      <td>2017-12-01T23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jørgen@obskorps</td>\n",
       "      <td>Det forventes at snødekket under mildværsgrens...</td>\n",
       "      <td>11</td>\n",
       "      <td>Nedsnødd eller nedføyket overflaterim</td>\n",
       "      <td>3</td>\n",
       "      <td>Mulig</td>\n",
       "      <td>2</td>\n",
       "      <td>Noen bratte heng</td>\n",
       "      <td>21</td>\n",
       "      <td>Liten tilleggsbelastning</td>\n",
       "      <td>...</td>\n",
       "      <td>3022</td>\n",
       "      <td>Trollheimen</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Mildvær har komprimert snødekket og dannet tyd...</td>\n",
       "      <td>210810</td>\n",
       "      <td>6991060</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-02T00:00:00</td>\n",
       "      <td>2017-12-02T23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jørgen@obskorps</td>\n",
       "      <td>Vind og godt med snø vil føre til dannelse av ...</td>\n",
       "      <td>11</td>\n",
       "      <td>Nedsnødd eller nedføyket overflaterim</td>\n",
       "      <td>3</td>\n",
       "      <td>Mulig</td>\n",
       "      <td>2</td>\n",
       "      <td>Noen bratte heng</td>\n",
       "      <td>21</td>\n",
       "      <td>Liten tilleggsbelastning</td>\n",
       "      <td>...</td>\n",
       "      <td>3022</td>\n",
       "      <td>Trollheimen</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Snødekket har blitt påvirket av mildvær i fler...</td>\n",
       "      <td>210810</td>\n",
       "      <td>6991060</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-03T00:00:00</td>\n",
       "      <td>2017-12-03T23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jørgen@obskorps</td>\n",
       "      <td>Vind og pågående snøvær vil føre til ytterlige...</td>\n",
       "      <td>11</td>\n",
       "      <td>Nedsnødd eller nedføyket overflaterim</td>\n",
       "      <td>3</td>\n",
       "      <td>Mulig</td>\n",
       "      <td>2</td>\n",
       "      <td>Noen bratte heng</td>\n",
       "      <td>21</td>\n",
       "      <td>Liten tilleggsbelastning</td>\n",
       "      <td>...</td>\n",
       "      <td>3022</td>\n",
       "      <td>Trollheimen</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Snødekket har blitt påvirket av mildvær i fler...</td>\n",
       "      <td>210810</td>\n",
       "      <td>6991060</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-04T00:00:00</td>\n",
       "      <td>2017-12-04T23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>torolav@obskorps</td>\n",
       "      <td>Kraftig vind og nedbør over tid gir store meng...</td>\n",
       "      <td>10</td>\n",
       "      <td>Nedføyket svakt lag med nysnø</td>\n",
       "      <td>3</td>\n",
       "      <td>Mulig</td>\n",
       "      <td>3</td>\n",
       "      <td>Mange bratte heng</td>\n",
       "      <td>21</td>\n",
       "      <td>Liten tilleggsbelastning</td>\n",
       "      <td>...</td>\n",
       "      <td>3022</td>\n",
       "      <td>Trollheimen</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Snødekket har blitt påvirket av mildvær i fler...</td>\n",
       "      <td>210810</td>\n",
       "      <td>6991060</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-05T00:00:00</td>\n",
       "      <td>2017-12-05T23:59:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Author                                    AvalancheDanger  \\\n",
       "0       Karsten@NVE  Forholdene er generelt stabile. I noen definer...   \n",
       "1   Jørgen@obskorps  Det forventes at snødekket under mildværsgrens...   \n",
       "2   Jørgen@obskorps  Vind og godt med snø vil føre til dannelse av ...   \n",
       "3   Jørgen@obskorps  Vind og pågående snøvær vil føre til ytterlige...   \n",
       "4  torolav@obskorps  Kraftig vind og nedbør over tid gir store meng...   \n",
       "\n",
       "   AvalancheProblems_0_AvalCauseId      AvalancheProblems_0_AvalCauseName  \\\n",
       "0                               10          Nedføyket svakt lag med nysnø   \n",
       "1                               11  Nedsnødd eller nedføyket overflaterim   \n",
       "2                               11  Nedsnødd eller nedføyket overflaterim   \n",
       "3                               11  Nedsnødd eller nedføyket overflaterim   \n",
       "4                               10          Nedføyket svakt lag med nysnø   \n",
       "\n",
       "   AvalancheProblems_0_AvalProbabilityId  \\\n",
       "0                                      3   \n",
       "1                                      3   \n",
       "2                                      3   \n",
       "3                                      3   \n",
       "4                                      3   \n",
       "\n",
       "  AvalancheProblems_0_AvalProbabilityName  \\\n",
       "0                                  Mulig    \n",
       "1                                  Mulig    \n",
       "2                                  Mulig    \n",
       "3                                  Mulig    \n",
       "4                                  Mulig    \n",
       "\n",
       "   AvalancheProblems_0_AvalPropagationId  \\\n",
       "0                                      1   \n",
       "1                                      2   \n",
       "2                                      2   \n",
       "3                                      2   \n",
       "4                                      3   \n",
       "\n",
       "  AvalancheProblems_0_AvalPropagationName  \\\n",
       "0                          Få bratte heng   \n",
       "1                        Noen bratte heng   \n",
       "2                        Noen bratte heng   \n",
       "3                        Noen bratte heng   \n",
       "4                       Mange bratte heng   \n",
       "\n",
       "   AvalancheProblems_0_AvalTriggerSimpleId  \\\n",
       "0                                       10   \n",
       "1                                       21   \n",
       "2                                       21   \n",
       "3                                       21   \n",
       "4                                       21   \n",
       "\n",
       "  AvalancheProblems_0_AvalTriggerSimpleName         ...          RegionId  \\\n",
       "0                   Stor tilleggsbelastning         ...              3022   \n",
       "1                  Liten tilleggsbelastning         ...              3022   \n",
       "2                  Liten tilleggsbelastning         ...              3022   \n",
       "3                  Liten tilleggsbelastning         ...              3022   \n",
       "4                  Liten tilleggsbelastning         ...              3022   \n",
       "\n",
       "    RegionName RegionTypeId  RegionTypeName  \\\n",
       "0  Trollheimen           10               A   \n",
       "1  Trollheimen           10               A   \n",
       "2  Trollheimen           10               A   \n",
       "3  Trollheimen           10               A   \n",
       "4  Trollheimen           10               A   \n",
       "\n",
       "                                         SnowSurface UtmEast  UtmNorth  \\\n",
       "0  Mildvær har komprimert snødekket og dannet tyd...  210810   6991060   \n",
       "1  Mildvær har komprimert snødekket og dannet tyd...  210810   6991060   \n",
       "2  Snødekket har blitt påvirket av mildvær i fler...  210810   6991060   \n",
       "3  Snødekket har blitt påvirket av mildvær i fler...  210810   6991060   \n",
       "4  Snødekket har blitt påvirket av mildvær i fler...  210810   6991060   \n",
       "\n",
       "  UtmZone            ValidFrom              ValidTo  \n",
       "0      33  2017-12-01T00:00:00  2017-12-01T23:59:59  \n",
       "1      33  2017-12-02T00:00:00  2017-12-02T23:59:59  \n",
       "2      33  2017-12-03T00:00:00  2017-12-03T23:59:59  \n",
       "3      33  2017-12-04T00:00:00  2017-12-04T23:59:59  \n",
       "4      33  2017-12-05T00:00:00  2017-12-05T23:59:59  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings, url = gf.get_warnings_as_json([3022, 3023, 3024], \"2017-12-01\", \"2018-05-31\", lang_key=1, simple=False, recursive_count=5)\n",
    "print(url)\n",
    "warnings_flattened = (flatten(w) for w in warnings)\n",
    "df = pd.DataFrame(warnings_flattened)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Author', 'AvalancheDanger', 'AvalancheProblems_0_AvalCauseId',\n",
       "       'AvalancheProblems_0_AvalCauseName',\n",
       "       'AvalancheProblems_0_AvalProbabilityId',\n",
       "       'AvalancheProblems_0_AvalProbabilityName',\n",
       "       'AvalancheProblems_0_AvalPropagationId',\n",
       "       'AvalancheProblems_0_AvalPropagationName',\n",
       "       'AvalancheProblems_0_AvalTriggerSimpleId',\n",
       "       'AvalancheProblems_0_AvalTriggerSimpleName',\n",
       "       ...\n",
       "       'RegionId', 'RegionName', 'RegionTypeId', 'RegionTypeName',\n",
       "       'SnowSurface', 'UtmEast', 'UtmNorth', 'UtmZone', 'ValidFrom',\n",
       "       'ValidTo'],\n",
       "      dtype='object', length=227)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define individual columns for avalanche problem 1 (AP1)\n",
    "df_a['AP1.AvalCauseId'] = np.nan\n",
    "df_a['AP1.AvalCauseName'] = ''\n",
    "df_a['AP1.AvalancheProblemTypeId'] = np.nan # AvalancheProblemTypeId\n",
    "df_a['AP1.AvalancheProblemTypeName'] = '' # AvalancheProblemTypeName\n",
    "df_a['AP1.DestructiveSizeExtId'] = np.nan # DestructiveSizeExtId\n",
    "df_a['AP1.DestructiveSizeExtName'] = ''\n",
    "df_a['AP1.AvalancheProblemId'] = np.nan\n",
    "df_a['AP1.AvalancheTypeId'] = np.nan\n",
    "df_a['AP1.AvalancheTypeName'] = ''\n",
    "df_a['AvalProbabilityId'] = np.nan\n",
    "df_a['AvalProbabilityName'] = ''\n",
    "df_a['AvalPropagationId'] = np.nan\n",
    "df_a['AvalPropagationName'] = ''\n",
    "df_a['AvalTriggerSimpleId'] = np.nan\n",
    "df_a['AvalTriggerSimpleName'] = ''\n",
    "\n",
    "df_a['AP1.Score'] = np.nan # APS score defined in /config/traininng_score.json and config/test_training_score.py\n",
    "#df_a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MountainWeather'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MountainWeather'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4f23ea5893c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MountainWeather'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MountainWeather'"
     ]
    }
   ],
   "source": [
    "df_a['MountainWeather'][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beaufort_scale = {'Stille/svak vind': 2, 'Bris': 4, 'Frisk bris': 5, 'Liten kuling': 6, 'Stiv kuling': 7, 'Sterk kuling': 8, 'Liten storm': 9, 'Storm': 10, 'Orkan': 12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See full list at http://api.nve.no/doc/snoeskredvarsel/#format\n",
    "\n",
    "- Precipitation (most exposed): MeasurementType=10; MeasurementSubType=60\n",
    "- Wind speed: MeasurementType=20; MeasurementSubType=20\n",
    "- Wind direction: MeasurementType=20; MeasurementSubType=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns for meteorological parameters\n",
    "df_a['Regional.PrecipitationMostExposed'] = np.nan\n",
    "df_a['Regional.PrecipitationAverage'] = np.nan\n",
    "df_a['Regional.WindSpeed'] = ''\n",
    "df_a['Regional.WindDirection'] = ''\n",
    "\n",
    "#df_a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_a.iterrows():\n",
    "    for mt in row['MountainWeather']['MeasurementTypes']:\n",
    "        #print(mt)\n",
    "        if mt['Id']==20: # wind\n",
    "            #print(mt['Name'])\n",
    "            for st in mt['MeasurementSubTypes']:\n",
    "                if st['Id'] == 20:\n",
    "                    df_a.loc[index, 'Regional.WindSpeed'] = beaufort_scale[st['Value']]\n",
    "                if st['Id'] == 50:\n",
    "                    df_a.loc[index, 'Regional.WindDirection'] = st['Value']\n",
    "        if mt['Id']==10: # precip\n",
    "            for st in mt['MeasurementSubTypes']:\n",
    "                if st['Id'] == 60:\n",
    "                    df_a.loc[index, 'Regional.PrecipitationMostExposed'] = st['Value']\n",
    "                if st['Id'] == 70:\n",
    "                    df_a.loc[index, 'Regional.PrecipitationAverage'] = st['Value']\n",
    "            #print(mt['Name'])\n",
    "\n",
    "        \n",
    "    for i in range(len(row['AvalancheProblems'])):\n",
    "        column_name_prefix = \"AP{0}\".format(row['AvalancheProblems'][i]['AvalancheProblemId'])\n",
    "        df_a.loc[index, '{0}.AvalCauseId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalCauseId']\n",
    "        df_a.loc[index, '{0}.AvalCauseName'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalCauseName']\n",
    "        df_a.loc[index, '{0}.AvalancheProblemTypeId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalancheProblemTypeId']\n",
    "        df_a.loc[index, '{0}.AvalancheProblemTypeName'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalancheProblemTypeName']\n",
    "        df_a.loc[index, '{0}.DestructiveSizeExtId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['DestructiveSizeExtId']\n",
    "        df_a.loc[index, '{0}.DestructiveSizeExtName'.format(column_name_prefix)] = row['AvalancheProblems'][i]['DestructiveSizeExtName']\n",
    "        df_a.loc[index, '{0}.AvalancheProblemId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalancheProblemId']\n",
    "        df_a.loc[index, '{0}.AvalancheTypeId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalancheTypeId']\n",
    "        df_a.loc[index, '{0}.AvalancheTypeName'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalancheTypeName']\n",
    "        df_a.loc[index, '{0}.AvalProbabilityId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalProbabilityId']\n",
    "        df_a.loc[index, '{0}.AvalProbabilityName'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalProbabilityName']\n",
    "        df_a.loc[index, '{0}.AvalPropagationId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalPropagationId']\n",
    "        df_a.loc[index, '{0}.AvalPropagationName'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalPropagationName']\n",
    "        df_a.loc[index, '{0}.AvalTriggerSimpleId'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalTriggerSimpleId']\n",
    "        df_a.loc[index, '{0}.AvalTriggerSimpleName'.format(column_name_prefix)] = row['AvalancheProblems'][i]['AvalTriggerSimpleName']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a['Regional.WindSpeed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List relevant parameters for the regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_score(position, size, distribution, trigger, probability, dangerlevel)\n",
    "ts = APSTrainingScore()\n",
    "print(ts.score_dict)\n",
    "print(ts.score_dict['DangerLevel'][str(int(df_a['DangerLevel'][1]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_a.iterrows():\n",
    "    ts.get_score(row['AP1.AvalancheProblemId'],\n",
    "                row['AP1.DestructiveSizeExtId'],\n",
    "                row['AP1.AvalPropagationId'],\n",
    "                row['AP1.AvalTriggerSimpleId'],\n",
    "                row['AP1.AvalProbabilityId'],\n",
    "                row['DangerLevel'])\n",
    "    df_a.loc[index, 'AP1.Score'] = ts.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df_a.drop(['CountyList', 'MunicipalityList'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a.to_csv('varsel_nordvestlandet_17_18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_a['DangerLevel'], df_a['AP1.Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ws = df_a[df_a['AP1.ProblemTypeId'] == 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl1 = go.Scatter(x = df_ws[df_ws[\"DangerLevel\"] == '1']['Regional.PrecipitationMostExposed'], y = df_ws[df_ws[\"DangerLevel\"] == '1']['Regional.WindSpeed'], name=\"Lowdanger\", mode='markers',\n",
    "                marker = {'size': 10, 'color': 'green'})\n",
    "dl2 = go.Scatter(x = df_ws[df_ws[\"DangerLevel\"] == '2']['Regional.PrecipitationMostExposed'], y = df_ws[df_ws[\"DangerLevel\"] == '2']['Regional.WindSpeed'], name=\"Moderate danger\", mode='markers',\n",
    "                marker = {'size': 10, 'color': 'yellow'})\n",
    "dl3 = go.Scatter(x = df_ws[df_ws[\"DangerLevel\"] == '3']['Regional.PrecipitationMostExposed'], y = df_ws[df_ws[\"DangerLevel\"] == '3']['Regional.WindSpeed'], name=\"Considerable danger\", mode='markers',\n",
    "                marker = {'size': 10, 'color': 'orange'})\n",
    "dl4 = go.Scatter(x = df_ws[df_ws[\"DangerLevel\"] == '4']['Regional.PrecipitationMostExposed'], y = df_ws[df_ws[\"DangerLevel\"] == '4']['Regional.WindSpeed'], name=\"High danger\", mode='markers',\n",
    "                marker = {'size': 10, 'color': 'red'})\n",
    "dl = go.Scatter(x = df_a['Regional.PrecipitationMostExposed'], y = df_a['Regional.WindSpeed'], name=\"All danger+problems\", mode='markers',\n",
    "                marker = {'size': 10, 'color': 'black'})\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Wind vs. precipitation (wind slabs)',\n",
    "              xaxis = dict(title = 'Precipitation'),\n",
    "              yaxis = dict(title = 'Wind speed'),\n",
    "              )\n",
    "pltdata = [dl, dl1, dl2, dl3, dl4]\n",
    "fig = dict(data=pltdata, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='precip_wind_dangerlevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For the purposes of this example, we store feature data from our\n",
    "### dataframe `df`, in the `f1` and `f2` arrays. We combine this into\n",
    "### a feature matrix `X` before entering it into the algorithm.\n",
    "f1 = np.array(df_a['Regional.PrecipitationMostExposed'].values, dtype=int)\n",
    "f2 = np.array(df_a['Regional.WindSpeed'].values)\n",
    "f3 = np.array(df_a['AP1.ProblemTypeId'].values)\n",
    "\n",
    "X = np.dstack((f1, f2, f3))[0]\n",
    "#print(X)\n",
    "kmeans = KMeans(n_clusters=4).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_\n",
    "#print(len(kmeans.labels_), len(f1), len(f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_class = go.Scatter(x = f1, y = f2, name=\"k-means classified\", mode='markers',\n",
    "                marker = {'size': 10, 'color': kmeans.labels_})\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Wind vs. precipitation - classified',\n",
    "              xaxis = dict(title = 'Precipitation'),\n",
    "              yaxis = dict(title = 'Wind speed'),\n",
    "              )\n",
    "class_data = [dl_class]\n",
    "fig = dict(data=class_data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='class_precip_wind_dangerlevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_f3 = go.Scatter(x = f1, y = f2, name=\"k-means classified\", mode='markers',\n",
    "                marker = {'size': 10, 'color': f3})\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Wind vs. precipitation - AP1-colored',\n",
    "              xaxis = dict(title = 'Precipitation'),\n",
    "              yaxis = dict(title = 'Wind speed'),\n",
    "              )\n",
    "ap1_data = [dl_f3]\n",
    "fig = dict(data=ap1_data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='precip_wind_AP1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# http://tst-h-int-api01/APSServices/TimeSeriesReader.svc/DistributionByDate/met_obs_v2.0/<værparameter>/24/<regions_id>.0/<fra_dato>/<til_dato>\n",
    "#met_url = r\"http://h-web03.nve.no/APSapi/TimeSeriesReader.svc/PrecipitationByDate/met_obs_v2.0/0/24/3024.0/2018-03-04/2018-03-04\"\n",
    "met_url = r'http://h-web03.nve.no/APSapi/TimeSeriesReader.svc/MountainWeather/3024.0/2018-03-04/no/true'\n",
    "met_data = requests.get(met_url).json()\n",
    "print(met_data)\n",
    "df_met = pd.DataFrame(met_data)\n",
    "print(df_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "clf = clf.fit(X, y)\n",
    "clf.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
