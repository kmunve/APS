{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graphs from varsom data using plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "\n",
    "#import plotly.offline as py\n",
    "#py.download_plotlyjs()\n",
    "#py.init_notebook_mode()\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3822 entries, 0 to 3821\n",
      "Columns: 101 entries, author to valid_to\n",
      "dtypes: datetime64[ns](3), float64(10), int64(46), object(42)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'../data/varsom/norwegian_avalanche_warnings_season_17_18.csv', index_col=0, parse_dates=['valid_from', 'valid_to', 'date_valid'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>avalanche_danger</th>\n",
       "      <th>avalanche_problem_1_advice</th>\n",
       "      <th>avalanche_problem_1_cause_id</th>\n",
       "      <th>avalanche_problem_1_cause_name</th>\n",
       "      <th>avalanche_problem_1_destructive_size_ext_id</th>\n",
       "      <th>avalanche_problem_1_destructive_size_ext_name</th>\n",
       "      <th>avalanche_problem_1_distribution_id</th>\n",
       "      <th>avalanche_problem_1_distribution_name</th>\n",
       "      <th>avalanche_problem_1_exposed_height_1</th>\n",
       "      <th>...</th>\n",
       "      <th>region_id</th>\n",
       "      <th>region_name</th>\n",
       "      <th>region_type_id</th>\n",
       "      <th>region_type_name</th>\n",
       "      <th>snow_surface</th>\n",
       "      <th>utm_east</th>\n",
       "      <th>utm_north</th>\n",
       "      <th>utm_zone</th>\n",
       "      <th>valid_from</th>\n",
       "      <th>valid_to</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karsten@NVE</td>\n",
       "      <td>Det er lite snø og generelt stabile forhold i ...</td>\n",
       "      <td>Vær varsom  der skredproblemet er å finne i ko...</td>\n",
       "      <td>15</td>\n",
       "      <td>Dårlig binding mellom lag i fokksnøen</td>\n",
       "      <td>2</td>\n",
       "      <td>2 - Middels</td>\n",
       "      <td>1</td>\n",
       "      <td>Få bratte heng</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3003</td>\n",
       "      <td>Nordenskiöld Land</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Det er generelt lite snø i terrenget. Rygger e...</td>\n",
       "      <td>520332</td>\n",
       "      <td>8663904</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017-12-01 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jan arild@obskorps</td>\n",
       "      <td>Kraftig vind fra sørøst vil gi pålagring av fe...</td>\n",
       "      <td>Vær forsiktig i områder brattere enn 30 grader...</td>\n",
       "      <td>10</td>\n",
       "      <td>Nedføyket svakt lag med nysnø</td>\n",
       "      <td>2</td>\n",
       "      <td>2 - Middels</td>\n",
       "      <td>2</td>\n",
       "      <td>Noen bratte heng</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>3007</td>\n",
       "      <td>Vest-Finnmark</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Siste dagene har det kommet 25-30 cm snø utsat...</td>\n",
       "      <td>802123</td>\n",
       "      <td>7794717</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017-12-01 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jan arild@obskorps</td>\n",
       "      <td>Generelle stabile forhold, men vindøkning fra ...</td>\n",
       "      <td>Vær forsiktig i områder brattere enn 30 grader...</td>\n",
       "      <td>10</td>\n",
       "      <td>Nedføyket svakt lag med nysnø</td>\n",
       "      <td>2</td>\n",
       "      <td>2 - Middels</td>\n",
       "      <td>2</td>\n",
       "      <td>Noen bratte heng</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>3009</td>\n",
       "      <td>Nord-Troms</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Siste dagene har det kommet 20-30 cm snø utsat...</td>\n",
       "      <td>750984</td>\n",
       "      <td>7742562</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017-12-01 23:59:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jan arild@obskorps</td>\n",
       "      <td>Vindøkning fra sør vil gi pålagring av fersk f...</td>\n",
       "      <td>Vær forsiktig i områder brattere enn 30 grader...</td>\n",
       "      <td>10</td>\n",
       "      <td>Nedføyket svakt lag med nysnø</td>\n",
       "      <td>2</td>\n",
       "      <td>2 - Middels</td>\n",
       "      <td>2</td>\n",
       "      <td>Noen bratte heng</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>3010</td>\n",
       "      <td>Lyngen</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>Siste dagene har det kommet 10-20 cm snø utsat...</td>\n",
       "      <td>692056</td>\n",
       "      <td>7719872</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>2017-12-01 23:59:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                   avalanche_danger  \\\n",
       "index                                                                          \n",
       "0             Karsten@NVE  Det er lite snø og generelt stabile forhold i ...   \n",
       "1      jan arild@obskorps  Kraftig vind fra sørøst vil gi pålagring av fe...   \n",
       "2      jan arild@obskorps  Generelle stabile forhold, men vindøkning fra ...   \n",
       "3      jan arild@obskorps  Vindøkning fra sør vil gi pålagring av fersk f...   \n",
       "\n",
       "                              avalanche_problem_1_advice  \\\n",
       "index                                                      \n",
       "0      Vær varsom  der skredproblemet er å finne i ko...   \n",
       "1      Vær forsiktig i områder brattere enn 30 grader...   \n",
       "2      Vær forsiktig i områder brattere enn 30 grader...   \n",
       "3      Vær forsiktig i områder brattere enn 30 grader...   \n",
       "\n",
       "       avalanche_problem_1_cause_id         avalanche_problem_1_cause_name  \\\n",
       "index                                                                        \n",
       "0                                15  Dårlig binding mellom lag i fokksnøen   \n",
       "1                                10          Nedføyket svakt lag med nysnø   \n",
       "2                                10          Nedføyket svakt lag med nysnø   \n",
       "3                                10          Nedføyket svakt lag med nysnø   \n",
       "\n",
       "       avalanche_problem_1_destructive_size_ext_id  \\\n",
       "index                                                \n",
       "0                                                2   \n",
       "1                                                2   \n",
       "2                                                2   \n",
       "3                                                2   \n",
       "\n",
       "      avalanche_problem_1_destructive_size_ext_name  \\\n",
       "index                                                 \n",
       "0                                       2 - Middels   \n",
       "1                                       2 - Middels   \n",
       "2                                       2 - Middels   \n",
       "3                                       2 - Middels   \n",
       "\n",
       "       avalanche_problem_1_distribution_id  \\\n",
       "index                                        \n",
       "0                                        1   \n",
       "1                                        2   \n",
       "2                                        2   \n",
       "3                                        2   \n",
       "\n",
       "      avalanche_problem_1_distribution_name  \\\n",
       "index                                         \n",
       "0                            Få bratte heng   \n",
       "1                          Noen bratte heng   \n",
       "2                          Noen bratte heng   \n",
       "3                          Noen bratte heng   \n",
       "\n",
       "       avalanche_problem_1_exposed_height_1         ...          region_id  \\\n",
       "index                                               ...                      \n",
       "0                                         0         ...               3003   \n",
       "1                                       400         ...               3007   \n",
       "2                                       400         ...               3009   \n",
       "3                                       400         ...               3010   \n",
       "\n",
       "             region_name  region_type_id region_type_name  \\\n",
       "index                                                       \n",
       "0      Nordenskiöld Land              10                A   \n",
       "1          Vest-Finnmark              10                A   \n",
       "2             Nord-Troms              10                A   \n",
       "3                 Lyngen              10                A   \n",
       "\n",
       "                                            snow_surface utm_east  utm_north  \\\n",
       "index                                                                          \n",
       "0      Det er generelt lite snø i terrenget. Rygger e...   520332    8663904   \n",
       "1      Siste dagene har det kommet 25-30 cm snø utsat...   802123    7794717   \n",
       "2      Siste dagene har det kommet 20-30 cm snø utsat...   750984    7742562   \n",
       "3      Siste dagene har det kommet 10-20 cm snø utsat...   692056    7719872   \n",
       "\n",
       "       utm_zone valid_from            valid_to  \n",
       "index                                           \n",
       "0            33 2017-12-01 2017-12-01 23:59:59  \n",
       "1            33 2017-12-01 2017-12-01 23:59:59  \n",
       "2            33 2017-12-01 2017-12-01 23:59:59  \n",
       "3            33 2017-12-01 2017-12-01 23:59:59  \n",
       "\n",
       "[4 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~karsten/41.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df[df.region_id==3034]['date_valid']\n",
    "y = df[df.region_id==3034]['danger_level']\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=y\n",
    "    )\n",
    "]\n",
    "py.iplot(data, filename='simple-bar-chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~karsten/43.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df[df.region_id==3034][\"mountain_weather_temperature_max\"] = np.where(df[df.region_id==3034][\"mountain_weather_temperature_max\"] <-50, np.nan)\n",
    "#df[df.region_id==3034][\"mountain_weather_temperature_max\"].replace(df[df.region_id==3034][\"mountain_weather_temperature_max\"] <-50, 0 ,inplace=True)\n",
    "\n",
    "x = df[df.region_id==3034]['date_valid']\n",
    "y1 = df[df.region_id==3034]['mountain_weather_precip_region']\n",
    "y2 = df[df.region_id==3034]['mountain_weather_temperature_max']#.replace(df[df.region_id==3034][\"mountain_weather_temperature_max\"] <-50, 0, inplace=True)\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=y1,\n",
    "        name='Precipitation'\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=x,\n",
    "        y=y2,\n",
    "        mode = 'lines+markers',  # 'lines' / 'markers'\n",
    "        name='Temperature'\n",
    "    )\n",
    "]\n",
    "py.iplot(data, filename='combined-line-bar-chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~karsten/35.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aw1718.plot.bar(x='date_valid', y=['avalanche_problem_1_destructive_size_ext_id', 'avalanche_problem_2_destructive_size_ext_id','avalanche_problem_3_destructive_size_ext_id'], ax = ax)\n",
    "_reg_id = 3034\n",
    "\n",
    "x = df[df.region_id==_reg_id]['date_valid']\n",
    "y1 = df[df.region_id==_reg_id]['avalanche_problem_1_destructive_size_ext_id']\n",
    "y2 = df[df.region_id==_reg_id]['avalanche_problem_2_destructive_size_ext_id']\n",
    "y3 = df[df.region_id==_reg_id]['avalanche_problem_3_destructive_size_ext_id']\n",
    "\n",
    "data = [\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=y1,\n",
    "        name='Problem 1'\n",
    "    ),\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=y2,\n",
    "        name='Problem 2'\n",
    "    ),\n",
    "    go.Bar(\n",
    "        x=x,\n",
    "        y=y3,\n",
    "        name='Problem 3'\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Grouped Bar with Pandas'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='pandas-bar-chart-layout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\plotly\\tools.py:1424: UserWarning:\n",
      "\n",
      "Looks like you used a newline character: '\\n'.\n",
      "\n",
      "Plotly uses a subset of HTML escape characters\n",
      "to do things like newline (<br>), bold (<b></b>),\n",
      "italics (<i></i>), etc. Your newline characters \n",
      "have been converted to '<br>' so they will show \n",
      "up right on your Plotly figure!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~karsten/37.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or more compact\n",
    "df_ = df[df.region_id==3014]\n",
    "data = []\n",
    "for i in range(1,4):\n",
    "    data.append(go.Bar(x=df_['date_valid'], y=df_[f'avalanche_problem_{i}_destructive_size_ext_id'], name=f'Problem {i}'))\n",
    "\n",
    "layout = go.Layout(\n",
    "    barmode = 'stack',\n",
    "    title = f'Avalanche size by avalanche problem\\nRegion: {df_.region_name.iloc[0]}'\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='aval_size_per_problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~karsten/55.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df[df.region_id==3014]\n",
    "x = df_['date_valid']\n",
    "y = ['Problem 1', 'Problem 2', 'Problem 3']\n",
    "z = []\n",
    "for i in range(1,4):\n",
    "    z.append(df_[f'avalanche_problem_{i}_destructive_size_ext_id'])\n",
    "\n",
    "trace = go.Heatmap(x=x, y=y, z=z,\n",
    "                  colorscale = 'Viridis')\n",
    "data=[trace]\n",
    "py.iplot(data, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nordvestlandet: Trollheimen, Romsdal, Sunnmøre\n",
    "warnings, url = gf.get_warnings_as_json([3022, 3023, 3024], \"2017-12-01\", \"2018-05-31\", lang_key=2, simple=False, recursive_count=5)\n",
    "\n",
    "# Østlandet: Jotunheimen, Hallingdal, Vest-Telemark\n",
    "#warnings, url = gf.get_warnings_as_json([3028, 3032, 3035], \"2017-12-01\", \"2018-05-31\", lang_key=2, simple=False, recursive_count=5)\n",
    "\n",
    "\n",
    "### Use this small data extraction for testing\n",
    "#warnings, url = gf.get_warnings_as_json([3022], \"2018-01-01\", \"2018-01-15\", lang_key=2, simple=False, recursive_count=5)\n",
    "\n",
    "print(url, '\\n\\n', type(warnings), len(warnings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(warnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since get_warnings_as_json returns a list, we have to apply \"flatten\" to each item... \n",
    "warnings_flattened = (flatten(w, root_keys_to_ignore={'CountyList', 'MunicipalityList'}) for w in warnings)\n",
    "# TODO: avalanche problems are not labeled correctly by their priority - need to correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(warnings_flattened)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the current dataset asa csv\n",
    "df.to_csv('forecasts_raw.csv', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create necessary columns and populate them\n",
    "error_count = 0\n",
    "log_file = r'./log/mountain_weather.log'\n",
    "logging.basicConfig(filename=log_file, level=logging.DEBUG)\n",
    "for index, row in df.iterrows():\n",
    "    for i in range(5):\n",
    "        for j in range(4):\n",
    "            try:\n",
    "                col_name = '{MWType} {MWSubType}'.format(MWType=row['MountainWeather_MeasurementTypes_{0}_Name'.format(i)], MWSubType=row['MountainWeather_MeasurementTypes_{0}_MeasurementSubTypes_{1}_Name'.format(i, j)])\n",
    "                col_name = col_name.replace(' ', '_')\n",
    "                if col_name in df.columns.values:\n",
    "                    df.loc[index, col_name] = row['MountainWeather_MeasurementTypes_{0}_MeasurementSubTypes_{1}_Value'.format(i, j)]\n",
    "                else:\n",
    "                    df[col_name] = np.nan\n",
    "                    print('Created column: ', col_name)\n",
    "                    df.loc[index, col_name] = row['MountainWeather_MeasurementTypes_{0}_MeasurementSubTypes_{1}_Value'.format(i, j)]\n",
    "                    \n",
    "                #print('{MWType} {MWSubType} = {MWSubTypeValue}'.format(MWType=df.loc[index]['MountainWeather_MeasurementTypes_{0}_Name'.format(i)],\n",
    "                 #                                                      MWSubType=df.loc[index]['MountainWeather_MeasurementTypes_{0}_MeasurementSubTypes_{1}_Name'.format(i, j)],\n",
    "                  #                                                     MWSubTypeValue=df.loc[index]['MountainWeather_MeasurementTypes_{0}_MeasurementSubTypes_{1}_Value'.format(i, j)]))\n",
    "            except KeyError:\n",
    "                error_count += 1\n",
    "                logging.info('MountainWeather_MeasurementTypes_{0}_MeasurementSubTypes_{1}... does not exist - moving on.'.format(i, j))\n",
    "print(f\"(Encountered {error_count} KeyError(s) - see log in {log_file})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove all MountainWeather_Measurement... columns\n",
    "# df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ValidFrom',\n",
    "    'Temperature_Max',\n",
    "    'Temperature_Min',\n",
    "    'Wind_Direction',\n",
    "    'Wind_Speed']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorial attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json-file with the wanted encoding\n",
    "with open(r'../config/snoskred_keys.json') as jdata:\n",
    "    snoskred_keys = json.load(jdata)\n",
    "\n",
    "# print content\n",
    "pprint(snoskred_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['AvalancheProblems_0_AvalPropagationId'].unique(), type(df['AvalancheProblems_0_AvalPropagationId'].unique()[0]))\n",
    "print(enc_df['Wind_Direction'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_df['Wind_Direction'].replace({None: 'Not given'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "wind_encoded = encoder.fit_transform(enc_df[\"Wind_Direction\"])\n",
    "\n",
    "for id_, class_ in enumerate(encoder.classes_):\n",
    "    print(f\"class id {id_} has label {class_}\")\n",
    "\n",
    "print()\n",
    "print(f\"Encoded wind direction values for first 10 entries: {wind_encoded[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change wind speeds to numerical values\n",
    "df['Wind_Speed_Num'] = df['Wind_Speed'].apply(lambda i: snoskred_keys['beaufort_scale_en'][i])\n",
    "df['Wind_Direction_Num'] = df['Wind_Direction'].apply(lambda i: 0 if i == None else snoskred_keys['wind_dir_conv_en'][i])\n",
    "\n",
    "# Re-group AvalancheProblemType\n",
    "# AvalancheProblemType grouped by PWL, wet slab, wet loose, dry loose, storm slab, and wind slab (and glide avalanche).\n",
    "df['AvalancheProblems_0_Class_AvalancheProblemType_Num'] = df['AvalancheProblems_0_AvalancheProblemTypeId'].apply(lambda i: 0 if i == np.nan else np.int(snoskred_keys['Class_AvalancheProblemTypeId'][str(int(i))]))\n",
    "df['AvalancheProblems_1_Class_AvalancheProblemType_Num'] = df['AvalancheProblems_1_AvalancheProblemTypeId'].apply(lambda i: 0 if str(i) == str(np.nan) else np.int(snoskred_keys['Class_AvalancheProblemTypeId'][str(int(i))]))\n",
    "\n",
    "# Distribution is labeled _Propagation_ in the API and has five classes. Change name to _AvalDistribution_ and merge the uper three classes into one called _widespread_.\n",
    "df['AvalancheProblems_0_Class_AvalDistribution_Num'] = df['AvalancheProblems_0_AvalPropagationId'].apply(lambda i: 0 if str(i) == str(np.nan) else np.int(snoskred_keys['Class_AvalDistributionId'][str(int(i))]))\n",
    "df['AvalancheProblems_1_Class_AvalDistribution_Num'] = df['AvalancheProblems_1_AvalPropagationId'].apply(lambda i: 0 if str(i) == str(np.nan) else np.int(snoskred_keys['Class_AvalDistributionId'][str(int(i))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns that hold numerical values.\n",
    "# AvalCause, AvalancheExt and AvalancheProblemType are directly correlated - keep only re-grouped ..._Class_AvalancheProblemType.\n",
    "df_numdata = df.filter(['AvalancheProblems_0_AvalProbabilityId',\n",
    "                        'AvalancheProblems_0_Class_AvalDistributionId',\n",
    "                        'AvalancheProblems_0_AvalTriggerSimpleId',\n",
    "                        'AvalancheProblems_0_AvalancheProblemId',\n",
    "                        'AvalancheProblems_0_Class_AvalancheProblemTypeId',\n",
    "                        'AvalancheProblems_0_AvalancheTypeId',\n",
    "                        'AvalancheProblems_0_DestructiveSizeExtId',\n",
    "                        'AvalancheProblems_1_AvalProbabilityId',\n",
    "                        'AvalancheProblems_1_Class_AvalDistributionId',\n",
    "                        'AvalancheProblems_1_AvalTriggerSimpleId',\n",
    "                        'AvalancheProblems_1_AvalancheProblemId',\n",
    "                        'AvalancheProblems_1_Class_AvalancheProblemTypeId',\n",
    "                        'AvalancheProblems_1_AvalancheTypeId',\n",
    "                        'AvalancheProblems_1_DestructiveSizeExtId',\n",
    "                        'DangerLevel',\n",
    "                        'ValidFrom',\n",
    "                        'Rainfall_Most_exposed_area',\n",
    "                        'Rainfall_Average',\n",
    "                        'Wind_Speed_Num',\n",
    "                        'Wind_Direction_Num',\n",
    "                        'Temperature_Min',\n",
    "                        'Temperature_Max',\n",
    "                        'Temperature_masl',\n",
    "                        'Freezing_Level_masl'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numdata.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are no weired values.\n",
    "for col in df_numdata.drop(['ValidFrom'], axis=1).columns.values:\n",
    "    print(col, ': ', df_numdata[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numdata.hist(bins=50, figsize=(25, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns without data\n",
    "#df_numdata = df_numdata.dropna(axis=1)\n",
    "\n",
    "df_numdata.to_csv('varsom_numdata.csv', index_label='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into a training- and test-dataset\n",
    "Randomly choose indicies that should serve a test data and which are removed from the training data.\n",
    "Maybe write a function that chooses a certain % as test dxata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle the index of nba.\n",
    "random_indices = np.random.permutation(df_numdata.index)\n",
    "# Set a cutoff for how many items we want in the test set (in this case 1/3 of the items)\n",
    "test_cutoff = np.int(np.floor(len(df_numdata)/3))\n",
    "print(test_cutoff)\n",
    "# Generate the test set by taking the first 1/3 of the randomly shuffled indices.\n",
    "df_test = df_numdata.loc[random_indices[1:test_cutoff]]\n",
    "# Generate the train set with the rest of the data.\n",
    "df_train = df_numdata.loc[random_indices[test_cutoff:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target variable in its own dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data = df_train.drop(['DangerLevel'], axis=1)\n",
    "df_test_data = df_test.drop(['DangerLevel'], axis=1)\n",
    "\n",
    "df_train_target = df_train.filter(['DangerLevel'], axis=1)\n",
    "df_test_target = df_test.filter(['DangerLevel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_data.to_csv('varsom_train_data.csv', index_label='index')\n",
    "df_test_data.to_csv('varsom_test_data.csv', index_label='index')\n",
    "\n",
    "df_train_target.to_csv('varsom_train_target.csv', index_label='index')\n",
    "df_test_target.to_csv('varsom_test_target.csv', index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
